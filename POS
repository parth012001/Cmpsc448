# Importing required libraries
import pandas as pd
import gzip

# Opening the gzipped text file and reading its content
with gzip.open('train.txt.gz', 'rt') as f:
    data = f.read()

# Splitting the content by newline to get individual lines
lines = data.split('\n')

# Splitting each line into tokens and filtering out empty lines
lines = [line.split() for line in lines if line]

# Creating a DataFrame with columns 'Token', 'POS tag', and 'Chunking tag'
df = pd.DataFrame(lines, columns=['Token', 'POS tag', 'Chunking tag'])

# Dropping the 'Chunking tag' column as it's not needed
df = df.drop('Chunking tag', axis=1)
print(df)

# Function to add previous and next word context to each token
def add_context(df):
    df["prev_word"] = df["Token"].shift(1)  # Add a new column for the previous word
    df["next_word"] = df["Token"].shift(-1)  # Add a new column for the next word
    df = df.fillna("NA")  # Fill NaN values (which occur for the first and last token) with "NA"
    return df

# Adding context to the DataFrame
df = add_context(df)

# Importing train-test split function
from sklearn.model_selection import train_test_split

# Splitting the data into training and test sets (80-20 split)
X_train, X_test, y_train, y_test = train_test_split(df['Token'], df['POS tag'], test_size=0.2, random_state=42)

# Importing required libraries for machine learning models
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report

# Naive Bayes Pipeline
# This pipeline includes a CountVectorizer for converting tokens to vectors,
# and a Multinomial Naive Bayes classifier for making predictions.
nb_pipeline = make_pipeline(
    CountVectorizer(analyzer='char_wb', ngram_range=(3, 5)), MultinomialNB()
)
nb_pipeline.fit(X_train, y_train)  # Training the Naive Bayes model
nb_predictions = nb_pipeline.predict(X_test)  # Making predictions on the test set

# Saving Naive Bayes results to a text file
nb_output_df = pd.DataFrame({'Token': X_test, 'True POS': y_test, 'Predicted POS': nb_predictions})
nb_output_df.to_csv('Bayesean_output.txt', index=False, sep='\t')

# Logistic Regression Pipeline
# This pipeline includes a CountVectorizer for converting tokens to vectors,
# and a Logistic Regression classifier for making predictions.
logreg_pipeline = make_pipeline(
    CountVectorizer(analyzer='char_wb', ngram_range=(3, 5)), LogisticRegression(max_iter=1000)
)
logreg_pipeline.fit(X_train, y_train)  # Training the Logistic Regression model
logreg_predictions = logreg_pipeline.predict(X_test)  # Making predictions on the test set

# Saving Logistic Regression results to a text file
logreg_output_df = pd.DataFrame({'Token': X_test, 'True POS': y_test, 'Predicted POS': logreg_predictions})
logreg_output_df.to_csv('log_output.txt', index=False, sep='\t')

# SVM Pipeline
# This pipeline includes a TfidfVectorizer for converting tokens to TF-IDF weighted vectors,
# and a Support Vector Machine classifier for making predictions.
svm_pipeline = make_pipeline(
    TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5)), SVC(kernel='linear')
)
svm_pipeline.fit(X_train, y_train)  # Training the SVM model
svm_predictions = svm_pipeline.predict(X_test)  # Making predictions on the test set

# Saving SVM results to a text file
svm_output_df = pd.DataFrame({'Token': X_test, 'True POS': y_test, 'Predicted POS': svm_predictions})
svm_output_df.to_csv('svm_output.txt', index=False, sep='\t')

